
## ðŸ§  Tokenization & Embedding Visualizer with BERT

This interactive Streamlit app lets you explore how **transformer-based language models** like **BERT** tokenize text and generate contextual **word/sentence embeddings**. You can input two sentences or words and visualize their tokenization along with a **semantic similarity score** based on **cosine similarity** of their `[CLS]` embeddings.

### ðŸš€ Features

* ðŸ”¤ Tokenize input text using `bert-base-uncased` tokenizer
* ðŸ§¬ Generate contextual embeddings using the BERT model
* ðŸ§  Compare semantic similarity between two inputs
* ðŸ“ˆ Visual display of tokenization and similarity score
* ðŸ’¡ Useful for understanding how embeddings and tokenization work in transformer models

### ðŸ§° Technologies Used

* [ðŸ¤— Transformers (BERT)](https://huggingface.co/bert-base-uncased) â€“ for tokenization and embedding generation
* [Streamlit](https://streamlit.io) â€“ for building the interactive web app
* [PyTorch](https://pytorch.org) â€“ underlying framework for running the model
* [Scikit-learn](https://scikit-learn.org) â€“ for computing cosine similarity



I built this project to get a clearer understanding of how **embeddings**, **tokenization**, and **semantic similarity** work under the hood using pre-trained language models. Itâ€™s a hands-on way to visualize what happens when you input text into BERT and how the model represents meaning.

